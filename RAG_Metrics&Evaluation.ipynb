{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjBcgAaagFtSpMoS8r7oHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doukansurel/Retrieval-Augmented-Generation/blob/main/RAG_Metrics%26Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3nE7ofq2JJX"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index==0.9.14.post3 deeplake==3.8.12 openai==1.3.8 cohere==4.37"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
        "os.environ[\"ACTIVELOOP_TOKEN\"] = \"ACTIVELOOP_TOKEN\""
      ],
      "metadata": {
        "id": "ROh4U7vI36et"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ServiceContext\n",
        "from llama_index.llms import OpenAI\n",
        "from llama_index.vector_stores import DeepLakeVectorStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "from llama_index import VectorStoreIndex"
      ],
      "metadata": {
        "id": "V58mKFMu4FFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad483779-8125-4488-90c7-3cba969c557f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.13) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build service context\n",
        "llm = OpenAI(model=\"gpt-4\",temperature=0.0)\n",
        "service_context = ServiceContext.from_defaults(llm=llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI2VUsQwX4a8",
        "outputId": "8b306f03-a36e-4f28-d0a5-b1b00de482cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 'data/paul_graham/'\n",
        "!curl 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -o 'data/paul_graham/paul_graham_essay.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfvQVDpu5BWM",
        "outputId": "6278e03e-aebe-4be9-d21a-dff02d92d965"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 75042  100 75042    0     0   269k      0 --:--:-- --:--:-- --:--:--  268k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "doc = SimpleDirectoryReader(\"/content/data/paul_graham\").load_data()\n",
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
        "nodes = node_parser.get_nodes_from_documents(doc)"
      ],
      "metadata": {
        "id": "HJxdlUB35HvC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = VectorStoreIndex(nodes)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ],
      "metadata": {
        "id": "FhHl9Hps43YZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(\n",
        "    documents=doc\n",
        ")"
      ],
      "metadata": {
        "id": "Lgrq4McL5SWc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.evaluation import FaithfulnessEvaluator\n",
        "\n",
        "#define evaluator\n",
        "evaluator = FaithfulnessEvaluator(service_context=service_context)\n",
        "\n",
        "#query index\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\n",
        "     \"What does Paul Graham do?\"\n",
        ")\n",
        "\n",
        "eval_results  = evaluator.evaluate_response(response=response)\n",
        "\n",
        "print( \"> response:\", response )\n",
        "\n",
        "print( \"> evaluator result:\", eval_results.passing )"
      ],
      "metadata": {
        "id": "jGG0muR75flr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f98ad3b-1d24-4ccd-cea0-1e606fd30d70"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> response: Paul Graham is a writer and entrepreneur. He has written numerous essays on various topics and has published them online. He has also authored a book called \"Hackers & Painters.\" In addition to writing, Paul Graham has worked on projects such as spam filters and has invested in startups as an angel investor. He is also one of the founders of Y Combinator, an angel firm.\n",
            "> evaluator result: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAGAS"
      ],
      "metadata": {
        "id": "saUHJNLRlGHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install html2text==2020.1.16 ragas==0.0.22"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqgedc8llGyB",
        "outputId": "7e11d772-2967-4a0f-c23f-ca66ebe890f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: pysbd, pyarrow-hotfix, jsonpointer, html2text, langsmith, jsonpatch, langchain-core, langchain-community, datasets, langchain, ragas\n",
            "Successfully installed datasets-2.16.0 html2text-2020.1.16 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.352 langchain-community-0.0.6 langchain-core-0.1.3 langsmith-0.0.75 pyarrow-hotfix-0.6 pysbd-0.3.4 ragas-0.0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "from llama_index import VectorStoreIndex, ServiceContext\n",
        "\n",
        "documents = SimpleWebPageReader(html_to_text=True).load_data( [\"https://en.wikipedia.org/wiki/New_York_City\"] )\n",
        "\n",
        "vector_index = VectorStoreIndex.from_documents(\n",
        "    documents, service_context=ServiceContext.from_defaults(chunk_size=512)\n",
        ")\n",
        "\n",
        "query_engine = vector_index.as_query_engine()\n",
        "\n",
        "response_vector = query_engine.query(\"How did New York City get its name?\")\n",
        "\n",
        "print(response_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNkCvigZlH4J",
        "outputId": "0f2e948c-66d2-4a8f-f940-bbe70aa529e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New York City got its name in honor of the Duke of York, who later became King James II of England. The Duke's elder brother, King Charles II, appointed him as the proprietor of the former territory of New Netherland, including the city of New Amsterdam, when England seized it from Dutch control.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelleri değerlendirme hedefimize dönersek, bir sonraki adım, daha doğru bir performans değerlendirmesi sağlamak için ideal olarak orijinal belgeden türetilmiş bir dizi soru oluşturmayı içerir."
      ],
      "metadata": {
        "id": "HlBwDKb2lZK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_questions = [\n",
        "    \"What is the population of New York City as of 2020?\",\n",
        "    \"Which borough of New York City has the highest population?\",\n",
        "    \"What is the economic significance of New York City?\",\n",
        "    \"How did New York City get its name?\",\n",
        "    \"What is the significance of the Statue of Liberty in New York City?\",\n",
        "]\n",
        "\n",
        "eval_answers = [\n",
        "    \"8,804,000\",  # incorrect answer\n",
        "    \"Queens\",  # incorrect answer\n",
        "    \"New York City's economic significance is vast, as it serves as the global financial capital, housing Wall Street and major financial institutions. Its diverse economy spans technology, media, healthcare, education, and more, making it resilient to economic fluctuations. NYC is a hub for international business, attracting global companies, and boasts a large, skilled labor force. Its real estate market, tourism, cultural industries, and educational institutions further fuel its economic prowess. The city's transportation network and global influence amplify its impact on the world stage, solidifying its status as a vital economic player and cultural epicenter.\",\n",
        "    \"New York City got its name when it came under British control in 1664. King Charles II of England granted the lands to his brother, the Duke of York, who named the city New York in his own honor.\",\n",
        "    \"The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.\",\n",
        "]\n",
        "\n",
        "eval_answers = [[a] for a in eval_answers]"
      ],
      "metadata": {
        "id": "MbAratMslPMz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu aşama değerlendirme sürecinin kurulum aşamasıdır. QueryEngine'in yeterliliği, bu belirli soruları ne kadar etkili bir şekilde işleyip yanıtladığına ve yanıtları performansı ölçmek için bir standart olarak kullanmasına göre değerlendirilir. Metrikleri Ragas kütüphanesinden içe aktarmamız gerekiyor."
      ],
      "metadata": {
        "id": "_2TRVWaAld4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas.metrics import(\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        ")\n",
        "from ragas.metrics.critique import harmfulness\n",
        "\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        "    harmfulness\n",
        "]"
      ],
      "metadata": {
        "id": "4Bo2MyS3leV_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrik listesi, metrikleri bir koleksiyon halinde derler; bu koleksiyon daha sonra QueryEngine performansının çeşitli yönlerini değerlendirmek için değerlendirme sürecinde kullanılabilir. Her metrik için puanları içeren sonuçlar daha ayrıntılı olarak analiz edilebilir. Son olarak değerlendirmeyi yapalım:"
      ],
      "metadata": {
        "id": "Est2FHFlmA86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas.llama_index import evaluate\n",
        "result  = evaluate(query_engine,metrics,eval_questions,eval_answers)\n",
        "\n",
        "#print the final scores\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBve33ICl57r",
        "outputId": "1f8dd99e-054a-46bd-e442-9341cb13627d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [faithfulness]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:15<00:00, 15.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [answer_relevancy]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:18<00:00, 18.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [context_precision]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [context_recall]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:05<00:00,  5.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [harmfulness]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'faithfulness': 0.8000, 'answer_relevancy': 0.7866, 'context_precision': 0.6000, 'context_recall': 0.8000, 'harmfulness': 0.0000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faithfulness:sistemin yanıtlarının kaynak materyalin gerçek içeriğine ne kadar doğru şekilde uyduğunu ölçer.bu, yanıtların çoğunlukla doğru ve kaynağa sadık olduğu anlamına gelir.\n",
        "\n",
        "answer_relevancy:sistemin yanıtlarının verilen sorgularla ne kadar alakalı olduğunu ölçer.\n",
        "\n",
        "context_precision:sistem tarafından yanıt oluşturmak için kullanılan bağlamın kesinliğini değerlendirir.\n",
        "context_recall:sistem tarafından belirlenen ilgili bağlamın geri çağrılma oranını ölçer.\n",
        "\n",
        "harmfulness:sistemi zararlı veya uygunsuz içerik üretimine yönelik ölçer. 0 puanı, değerlendirilen yanıtlarda zararlı içerik üretilmediğini ifade eder."
      ],
      "metadata": {
        "id": "4dT3ZR8fmnvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Custom RAG Pipeline Evaluation"
      ],
      "metadata": {
        "id": "sLG6YKHbnT31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/idontcalculate/data-repo/main/venus_transmission.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpSAjYeemUxl",
        "outputId": "c8103ecf-12b7-4474-cc5f-fc5ed45a78e0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-29 12:47:21--  https://raw.githubusercontent.com/idontcalculate/data-repo/main/venus_transmission.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19241 (19K) [text/plain]\n",
            "Saving to: ‘venus_transmission.txt’\n",
            "\n",
            "\rvenus_transmission.   0%[                    ]       0  --.-KB/s               \rvenus_transmission. 100%[===================>]  18.79K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-12-29 12:47:22 (27.6 MB/s) - ‘venus_transmission.txt’ saved [19241/19241]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "reader = SimpleDirectoryReader(input_files=[\"/content/venus_transmission.txt\"])\n",
        "\n",
        "docs = reader.load_data()\n",
        "print(f\"Loaded {len(docs)} docs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs6ZaWFZnbp_",
        "outputId": "3956110e-88e5-4c8b-ce03-6d10fd1f1ce6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1 docs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SimpleNodeParser, bu bağlamda, belgeleri düğümler olarak bilinen yapılandırılmış bir formata dönüştürür ve özellikle yığın boyutunu tanımlama, örtüşmeyi yönetme ve meta verileri birleştirme açısından belgelerin ayrıştırılmasında özelleştirmeye hizmet eder. Belgenin her bir parçası bir düğüm olarak değerlendirilir. Bu durumda ayrıştırıcının chunk_size değeri 512 olarak ayarlanır; bu, her düğümün orijinal belgedeki 512 karakterden oluşacağı anlamına gelir. Bu parçalar daha sonra indeksleri oluşturmak için kullanılabilir."
      ],
      "metadata": {
        "id": "ejoraVJ9nyB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "from llama_index import VectorStoreIndex\n",
        "\n",
        "#Build İndex with a chunk_size of 512\n",
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
        "nodes =node_parser.get_nodes_from_documents(docs)\n",
        "vector_index = VectorStoreIndex(nodes)"
      ],
      "metadata": {
        "id": "3Hrfhp8Cnq_V"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine()\n",
        "\n",
        "response_vector = query_engine.query(\"What was The first beings to inhabit the planet?\")\n",
        "print( response_vector.response )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JTeXxTdoHkH",
        "outputId": "5d83e48a-8adb-4c86-868a-4b1a24226acb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first beings to inhabit the planet were a dinoid and reptoid race from two different systems outside our solar system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorgu motoru tarafından oluşturulan yanıt, yanıt_vektöründe depolanır. Böylece belge düğümlere işlenir, dizine eklenir ve ardından bir dil modeli kullanılarak sorgulanır. Yanıtı daha ayrıntılı araştırmak için, soruyu yanıtlamak için kullanılan dizinden alınan belgeye erişmek üzere .source_nodes anahtarını kullanabiliriz."
      ],
      "metadata": {
        "id": "YzRfhDM2ocRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First retrieved node\n",
        "response_vector.source_nodes[0].get_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "uulRiFnTociE",
        "outputId": "9baa00e5-b8a3-4ac2-dfca-1e5785279c9c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"They had heard of this beautiful new planet. At this time, Earth had two moons to harmonize the weather conditions and control the tides of the large bodies of water.\\nThe first beings to inhabit the planet were a dinoid and reptoid race from two different systems outside our solar system. They were intelligent and walked on two legs like humans and were war-like considering themselves to be superior to all other life forms. In the past, the four races of humans had conflicts with them before they outgrew such behavior. They arrived on Earth to rob it of its minerals and valuable gems. Soon they had created a terrible war. They were joined by re-\\n1\\nenforcements from their home planets. One set up its base on one of the Earth's moons, the other on Earth. It was a terrible war with advanced nuclear and laser weapons like you see in your science fiction movies. It lasted very long. Most of the life forms lay in singed waste and the one moon was destroyed. No longer interested in Earth, they went back to their planets leaving their wounded behind, they had no use for them.\\nThe four races sent a few forces to see if they could help the wounded dinoids and reptilians and to see what they could do to repair the Earth. They soon found that due to the nuclear radiation it was too dangerous on Earth before it was cleared. Even they had to remain so as not to contaminate their own planets.\\nDue to the radiation, the survivors of the dinoids and reptoids mutated into the Dinosaurs and giant reptilians you know of in your history. The humans that were trapped there mutated into what you call Neanderthals.\\nThe Earth remained a devastated ruin, covered by a huge dark nuclear cloud and what vegetation was left was being devoured by the giant beings, also humans and animals by some. It was this way for hundreds of years before a giant comet crashed into one of the oceans and created another huge cloud. This created such darkness that the radiating heat of the Sun could not interact with Earth's gravitational field and an ice age was created. This destroyed the mutated life forms and gave the four races the chance to cleanse and heal the Earth with technology and their energy.\\nOnce again, they brought various forms of life to the Earth, creating again a paradise, except for extreme weather conditions and extreme tidal activities.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_vector.source_nodes[1].get_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "21j4OY41ojs_",
        "outputId": "2b360428-c8db-4a1c-d026-76e6008b5be6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Due to the radiation, the survivors of the dinoids and reptoids mutated into the Dinosaurs and giant reptilians you know of in your history. The humans that were trapped there mutated into what you call Neanderthals.\\nThe Earth remained a devastated ruin, covered by a huge dark nuclear cloud and what vegetation was left was being devoured by the giant beings, also humans and animals by some. It was this way for hundreds of years before a giant comet crashed into one of the oceans and created another huge cloud. This created such darkness that the radiating heat of the Sun could not interact with Earth's gravitational field and an ice age was created. This destroyed the mutated life forms and gave the four races the chance to cleanse and heal the Earth with technology and their energy.\\nOnce again, they brought various forms of life to the Earth, creating again a paradise, except for extreme weather conditions and extreme tidal activities.\\nDuring this time they realized that their planets were going into a natural dormant stage that they would not be able to support physical life. So they decided to colonize the Earth with their own people. They were concerned about the one moon, because it is creating earthquakes and tidal waves and storms and other difficulties for the structure of the Earth. They knew how to drink fluids to protect and balance themselves. These were the first colonies like Atlantis and Lemuria.\\nThe rest of the people stayed on their planets to await their destiny. They knew that they would perish and die. They had made the decision only to bring the younger generation with some spiritual teachers and elders to the Earth. The planet was too small for all of them. But they had no fear of death.\\nThey had once again created a paradise. They were instructed to build special temples here as doorways to the other dimensions. Because of the aggressive beings, the temples were hidden for future times when they will be important. There they could do their meditations and the higher beings.\\nThey were informed to build two shields around the Earth out of ice particles to balance the influence of the one moon. They created a tropical climate for the Earth. There were no deserts at that time. They have special crystals for these doorways and they were able to lower their vibration to enter through these doorways. The news spread of the beautiful planet.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorgu motorunun ilgili bulduğu ikinci düğümden gelen metinsel bilgileri görüntüleyebilir ve sorguya yanıt olarak ek bağlam veya bilgi sağlayabilirsiniz. Bu, sorgu motorunun elde ettiği bilginin genişliğini ve dizine eklenen belgelerin farklı bölümlerinin genel yanıta nasıl katkıda bulunduğunu anlamaya yardımcı olur."
      ],
      "metadata": {
        "id": "wONd9h2voqZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate_question_context_pairs sınıfı, her düğümün içeriğine dayalı sorular oluşturmak için LLM'den yararlanır: Her düğüm için iki soru oluşturulacak ve sonuçta her öğenin bir bağlamdan (düğümün metni) ve karşılık gelen bir soru grubundan oluştuğu bir veri kümesi elde edilecektir. Soru-Cevap veri seti, bir RAG sisteminin soru oluşturma ve bağlam anlama görevlerindeki yeteneklerini değerlendirmemize hizmet edecektir."
      ],
      "metadata": {
        "id": "25OOHa8epUXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import OpenAI\n",
        "from llama_index.evaluation import generate_question_context_pairs\n",
        "\n",
        "#Define an LLm\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "qa_dataset = generate_question_context_pairs(\n",
        "    nodes,\n",
        "    llm=llm,\n",
        "    num_questions_per_chunk=2\n",
        ")\n",
        "\n",
        "queries = list(qa_dataset.queries.values())\n",
        "print(queries[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbGC-qrboqo-",
        "outputId": "ad3d4596-d15b-4961-f9af-34e8878d7b63"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:23<00:00,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['How did the beings described in the context information communicate with different life forms and dimensions? How did their telepathic abilities and technology contribute to their understanding of creation and the creator?', 'Describe the role of different races in the colonization of planets within our solar system, as mentioned in the context information. How did Earth differ from other planets during that time period and what was its status in relation to the other planets?', 'Explain the concept of creativity as understood by the advanced beings in the context. How did they use their creative energy and what were the responsibilities associated with it?', 'Describe the initial state of Earth before it became a planet and settled into an orbit around the Sun. How did the four races of humans contribute to the development of life on Earth?', \"How did the arrival of the dinoid and reptoid races on Earth lead to a devastating war? Discuss the reasons behind their conflict with the four races of humans and the consequences of their actions on Earth's environment.\", \"Explain the process of mutation that occurred among the survivors of the dinoids and reptoids, resulting in the emergence of dinosaurs and Neanderthals. Discuss the role of nuclear radiation and its impact on the Earth's ecosystem during this period.\", 'How did the survivors of the radiation in the context mutate into different species? Explain the process and the resulting species.', 'Describe the events that led to the creation of an ice age on Earth. How did this ice age affect the mutated life forms and what opportunity did it provide for the four races?', 'Explain the purpose and significance of building special temples as doorways to other dimensions in the context of the given information. How did these temples serve as a means of protection against the dark forces?', 'Discuss the actions taken by the colonies in response to the war declared by another race of humans. How did the destruction of Lemuria and Atlantis contribute to preventing the misuse of knowledge and technology by the dark forces?']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.evaluation import RetrieverEvaluator\n",
        "\n",
        "retriever = vector_index.as_retriever(similarity_top_k=2)\n",
        "\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\",\"hit_rate\"],retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "zcd1hwnlqecB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate\n",
        "import pandas as pd\n",
        "\n",
        "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)\n",
        "\n",
        "def display_results(name,eval_results):\n",
        "\n",
        "    metric_dicts = []\n",
        "    for eval_result in eval_results:\n",
        "        metric_dict = eval_result.metric_vals_dict\n",
        "        metric_dicts.append(metric_dict)\n",
        "\n",
        "    full_df = pd.DataFrame(metric_dicts)\n",
        "\n",
        "    hit_rate = full_df[\"hit_rate\"].mean()\n",
        "    mrr = full_df[\"mrr\"].mean()\n",
        "\n",
        "    metric_df = pd.DataFrame(\n",
        "        {\"Retriever Name\": [name], \"Hit Rate\": [hit_rate], \"MRR\": [mrr]}\n",
        "    )\n",
        "\n",
        "    return metric_df\n",
        "\n",
        "display_results(\"OpenAI Embedding Retriever\", eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "m_7P147lrHqu",
        "outputId": "6768adad-3bd6-47fd-9238-3314f0ef5334"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Retriever Name  Hit Rate       MRR\n",
              "0  OpenAI Embedding Retriever  0.923077  0.807692"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad943d8d-33c4-438e-a4e9-47f3fe8cff00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Retriever Name</th>\n",
              "      <th>Hit Rate</th>\n",
              "      <th>MRR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OpenAI Embedding Retriever</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.807692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad943d8d-33c4-438e-a4e9-47f3fe8cff00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad943d8d-33c4-438e-a4e9-47f3fe8cff00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad943d8d-33c4-438e-a4e9-47f3fe8cff00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt-3.5-turbo\n",
        "gpt35 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "service_context_gpt35 = ServiceContext.from_defaults(llm=gpt35)\n",
        "\n",
        "# gpt-4\n",
        "gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n",
        "service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)\n",
        "\n",
        "vector_index = VectorStoreIndex(nodes, service_context = service_context_gpt35)\n",
        "query_engine = vector_index.as_query_engine()\n",
        "\n",
        "eval_query = queries[10]\n",
        "response_vector = query_engine.query(eval_query)\n",
        "\n",
        "print( \"> eval_query: \", eval_query )\n",
        "print( \"> response_vector:\", response_vector )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFs0xLcVrVy_",
        "outputId": "0a8e2f3c-dc90-4d89-b350-4b9464c3c197"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> eval_query:  How did the colonies respond to the declaration of war by the dark forces, and what measures did they take to protect their knowledge and technology?\n",
            "> response_vector: The colonies did not fight back against the dark forces when they declared war. Instead, they sent most of their people into hiding in order to rebuild the colonies later. They also destroyed everything to ensure that their knowledge and technology would not fall into the hands of the dark forces. Additionally, Lemuria and Atlantis were destroyed by their inhabitants to prevent the misuse of their knowledge and technology by the dark forces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Artık her bir metriğin ölçülmesinden sorumlu değerlendirici sınıflarını oluşturabiliriz. Daha sonra test kriterlerini karşılayıp karşılamadığını belirlemek için örnek bir yanıt kullanacağız."
      ],
      "metadata": {
        "id": "x1D-CykgrzHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.evaluation import RelevancyEvaluator\n",
        "from llama_index.evaluation import FaithfulnessEvaluator\n",
        "\n",
        "relevancy_gpt4 = RelevancyEvaluator(service_context=service_context_gpt4)\n",
        "faithfulness_gpt4 = FaithfulnessEvaluator(service_context=service_context_gpt4)\n",
        "\n",
        "# Compute faithfulness evaluation\n",
        "\n",
        "eval_result = faithfulness_gpt4.evaluate_response(response=response_vector)\n",
        "# check passing parameter in eval_result if it passed the evaluation.\n",
        "print( eval_result.passing )\n",
        "\n",
        "# Relevancy evaluation\n",
        "eval_result = relevancy_gpt4.evaluate_response(\n",
        "    query=eval_query, response=response_vector\n",
        ")\n",
        "# You can check passing parameter in eval_result if it passed the evaluation.\n",
        "print( eval_result.passing )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A9HpOFErwmp",
        "outputId": "60723a4f-3716-46d0-dd2a-da5deb36aa94"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Her bir örneği değerlendirme veri setinden beslemek ve uygun sonuçları almak için bir for döngüsü gerçekleştirmeliyiz. Bu durumda değerlendirme sürecini toplu ve eş zamanlı çalıştıran LlamaIndex BatchEvalRunner sınıfını kullanabiliriz. Bu, değerlendirmenin daha hızlı yapılabileceği anlamına gelir."
      ],
      "metadata": {
        "id": "aRM_85zTr4Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.evaluation import BatchEvalRunner\n",
        "\n",
        "# Let's pick top 10 queries to do evaluation\n",
        "batch_eval_queries = queries[:10]\n",
        "\n",
        "# Initiate BatchEvalRunner to compute FaithFulness and Relevancy Evaluation.\n",
        "runner = BatchEvalRunner(\n",
        "    {\"faithfulness\": faithfulness_gpt4, \"relevancy\": relevancy_gpt4},\n",
        "    workers=8,\n",
        ")\n",
        "\n",
        "# Compute evaluation\n",
        "eval_results = await runner.aevaluate_queries(\n",
        "    query_engine, queries=batch_eval_queries\n",
        ")\n",
        "\n",
        "# get faithfulness score\n",
        "faithfulness_score = sum(result.passing for result in eval_results['faithfulness']) / len(eval_results['faithfulness'])\n",
        "# get relevancy score\n",
        "relevancy_score = sum(result.passing for result in eval_results['faithfulness']) / len(eval_results['relevancy'])\n",
        "\n",
        "print( \"> faithfulness_score\", faithfulness_score )\n",
        "print( \"> relevancy_score\", relevancy_score )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwDRGS78r4lM",
        "outputId": "abbed5aa-7d99-468d-a22c-938ea5600316"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> faithfulness_score 1.0\n",
            "> relevancy_score 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Toplu işleme yöntemi, sistemin performansının bir dizi farklı sorgu üzerinden hızlı bir şekilde değerlendirilmesine yardımcı olur. 1,0'lık bir doğruluk puanı, oluşturulan yanıtların halüsinasyon içermediğini ve tamamen alınan bağlama dayandığını gösterir. Ayrıca 1,0 olan Uygunluk puanı, oluşturulan yanıtların, alınan bağlam ve sorgularla tutarlı bir şekilde uyumlu olduğunu gösterir."
      ],
      "metadata": {
        "id": "Kszu8MAAsDyf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RF2G6RjRsEIl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}